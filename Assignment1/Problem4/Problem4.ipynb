{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b_d_jbqWY5OB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision.models.vgg import vgg16\n",
        "from torchvision.models.alexnet import alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzDRWcvP7YBZ",
        "outputId": "41617c53-762b-47dc-fc11-7f75c79c909f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2oSidMv-AaQ_"
      },
      "outputs": [],
      "source": [
        "transform  = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vTi2Dfk6Y9g2"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "  alex_feature = []\n",
        "  alex_label = []\n",
        "\n",
        "  vgg16_feature = []\n",
        "  vgg16_label = []\n",
        "\n",
        "  train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "  # test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "  #                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "  # [Problem 4 a.] IMPORT VGG16 AND ALEXNET FROM THE MODELS FOLDER WITH\n",
        "  # PRETRAINED = TRUE\n",
        "\n",
        "\n",
        "  vgg16_extractor = vgg16(pretrained=True).to(device)\n",
        "  # vgg16_extractor = vgg16(pretrained=True)\n",
        "  vgg16_extractor.eval()\n",
        "\n",
        "  # alex_extractor = alexnet(pretrained=True)\n",
        "  alex_extractor = alexnet(pretrained=True).to(device)\n",
        "  alex_extractor.eval()\n",
        "\n",
        "\n",
        "  for idx, data in enumerate(train_data):\n",
        "\n",
        "      image, label = data\n",
        "\n",
        "      image = image.to(device)\n",
        "\n",
        "      #Forward pass through VGG16\n",
        "      with torch.no_grad():\n",
        "          F_vgg = vgg16_extractor(image.unsqueeze(0))\n",
        "          vgg16_feature.append(F_vgg.flatten().cpu().numpy())  # Move back to CPU\n",
        "          vgg16_label.append(label)\n",
        "\n",
        "      # Forward pass through AlexNet\n",
        "      with torch.no_grad():\n",
        "          F_alex = alex_extractor(image.unsqueeze(0))\n",
        "          alex_feature.append(F_alex.flatten().cpu().numpy())  # Move back to CPU\n",
        "          alex_label.append(label)\n",
        "\n",
        "\n",
        "  sio.savemat('vgg16.mat', mdict={'feature': alex_feature, 'label': alex_label})\n",
        "  sio.savemat('alexnet.mat', mdict={'feature': vgg16_feature, 'label': vgg16_label})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X36nfNo3ZB0g"
      },
      "outputs": [],
      "source": [
        "def KNN_test(test_data, K=1):\n",
        "    # Load the saved .mat files\n",
        "    vgg_mat = sio.loadmat('vgg16.mat')['feature']\n",
        "    alex_mat = sio.loadmat('alexnet.mat')['feature']\n",
        "    alex_labels = sio.loadmat('alexnet.mat')['label'].flatten()\n",
        "\n",
        "    # Load models and move to GPU if available\n",
        "    vgg16_extractor = vgg16(pretrained=True).to(device)\n",
        "    alex_extractor = alexnet(pretrained=True).to(device)\n",
        "\n",
        "    vgg16_accuracy = 0\n",
        "    alex_accuracy = 0\n",
        "\n",
        "    for idx, (data, label) in enumerate(test_data):\n",
        "        if idx == 300:\n",
        "            break\n",
        "        # 1. EXTRACT FEATURES USING THE MODELS - ALEXNET AND VGG16\n",
        "        data = data.unsqueeze(0).to(device)  # Add batch dimension and move to GPU\n",
        "        with torch.no_grad():\n",
        "            F_test_vgg16 = vgg16_extractor(data).flatten().cpu().numpy()\n",
        "            F_test_alex = alex_extractor(data).flatten().cpu().numpy()\n",
        "\n",
        "        # 2. FIND NEAREST NEIGHBOR OF THIS FEATURE FROM FEATURES STORED IN ALEXNET.MAT AND VGG16.MAT\n",
        "        nbrs_vgg = NearestNeighbors(n_neighbors=K, algorithm='ball_tree').fit(vgg_mat)\n",
        "        distances_vgg, indices_vgg = nbrs_vgg.kneighbors([F_test_vgg16])\n",
        "\n",
        "        nbrs_alex = NearestNeighbors(n_neighbors=K, algorithm='ball_tree').fit(alex_mat)\n",
        "        distances_alex, indices_alex = nbrs_alex.kneighbors([F_test_alex])\n",
        "\n",
        "        # 3. COMPUTE ACCURACY\n",
        "        # The labels are the K-nearest neighbor labels, not indices, so we need to extract them\n",
        "        vgg16_nearest_labels = [alex_labels[ind] for ind in indices_vgg[0]]\n",
        "        alex_nearest_labels = [alex_labels[ind] for ind in indices_alex[0]]\n",
        "\n",
        "        vgg16_accuracy += accuracy_score([label], vgg16_nearest_labels)\n",
        "        alex_accuracy += accuracy_score([label], alex_nearest_labels)\n",
        "\n",
        "    vgg16_accuracy /= len(test_data)\n",
        "    alex_accuracy /= len(test_data)\n",
        "\n",
        "    return vgg16_accuracy, alex_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27SZYmC-ZD0z",
        "outputId": "c0771424-64ef-457d-e0ce-b076581e8651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zwFLYe36BtFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03894f5-60f7-4be6-ca4c-9579dbcb0334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16 Accuracy: 0.52\n",
            "AlexNet Accuracy: 0.46\n"
          ]
        }
      ],
      "source": [
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Test using KNN\n",
        "vgg16_acc, alex_acc = KNN_test(test_data)\n",
        "print(\"VGG16 Accuracy:\", vgg16_acc)\n",
        "print(\"AlexNet Accuracy:\", alex_acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}